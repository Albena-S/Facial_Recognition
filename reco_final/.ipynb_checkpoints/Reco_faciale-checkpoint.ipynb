{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29ad17b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! python -m pip install --user opencv-contrib-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67dadb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfc0fe9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_dataset (images_class, label) :\n",
    "    # show doata for 1 class\n",
    "    plt.figure(figsize = (14,5))\n",
    "    k = 0\n",
    "    for i in range(1,6):\n",
    "        plt.subplot(1,5,i)\n",
    "        try :\n",
    "            plt.imshow(images_class[k][:, :, ::-1])\n",
    "        except :\n",
    "            plt.imshow(images_class[k], cmap = 'gray')\n",
    "        plt.title(label)\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        k += 1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c07c4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset_folder = \"lib_small/\"\n",
    "dataset_folder = \"dataset/\"\n",
    "\n",
    "names = []\n",
    "images = []\n",
    "for folder in os.listdir(dataset_folder):\n",
    "    for name in os.listdir(os.path.join(dataset_folder, folder))[:70]: #limit nb of faces per class to 70\n",
    "        img = cv2.imread(os.path.join(dataset_folder + folder, name))\n",
    "        images.append(img)\n",
    "        names.append(folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06abee78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Albena', 'AlexandreF', 'AlexandreL', 'AlexandreS', 'Ange',\n",
       "       'Aurélien', 'Camille', 'Dorian', 'Erwan', 'Florentin', 'Gauthier',\n",
       "       'Khélian', 'Marius', 'Mathieu', 'Maxime', 'Nouveau dossier',\n",
       "       'Samuel', 'Sylvain', 'Thomas', 'ThomasS', 'Unknown'], dtype='<U15')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.unique(names)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e407da4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in labels:\n",
    "    ids = np.where(label == np.array(names))[0]\n",
    "    images_class = images[ids[0] : ids[-1] + 1]\n",
    "    #show_dataset(images_class, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee60d794",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_eye.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30222e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266\n",
      "266\n",
      "['Albena', 'Albena', 'Albena', 'Albena', 'Albena', 'Albena', 'Albena', 'Albena', 'Albena', 'Albena', 'Albena', 'Albena', 'Albena', 'Albena', 'Albena', 'AlexandreF', 'AlexandreF', 'AlexandreF', 'AlexandreF', 'AlexandreF', 'AlexandreF', 'AlexandreF', 'AlexandreF', 'AlexandreF', 'AlexandreF', 'AlexandreF', 'AlexandreF', 'AlexandreF', 'AlexandreF', 'AlexandreF', 'AlexandreL', 'AlexandreL', 'AlexandreL', 'AlexandreL', 'AlexandreL', 'AlexandreL', 'AlexandreL', 'AlexandreL', 'AlexandreL', 'AlexandreL', 'AlexandreL', 'AlexandreL', 'AlexandreL', 'AlexandreL', 'AlexandreL', 'AlexandreS', 'AlexandreS', 'AlexandreS', 'AlexandreS', 'AlexandreS', 'AlexandreS', 'AlexandreS', 'AlexandreS', 'AlexandreS', 'AlexandreS', 'AlexandreS', 'AlexandreS', 'AlexandreS', 'AlexandreS', 'AlexandreS', 'Ange', 'Ange', 'Ange', 'Ange', 'Ange', 'Ange', 'Ange', 'Ange', 'Ange', 'Ange', 'Ange', 'Ange', 'Ange', 'Ange', 'Ange', 'Aurélien', 'Aurélien', 'Aurélien', 'Aurélien', 'Aurélien', 'Aurélien', 'Aurélien', 'Aurélien', 'Aurélien', 'Aurélien', 'Aurélien', 'Aurélien', 'Aurélien', 'Aurélien', 'Camille', 'Camille', 'Camille', 'Camille', 'Camille', 'Camille', 'Camille', 'Camille', 'Camille', 'Camille', 'Camille', 'Camille', 'Camille', 'Camille', 'Camille', 'Dorian', 'Dorian', 'Dorian', 'Dorian', 'Dorian', 'Dorian', 'Dorian', 'Dorian', 'Dorian', 'Dorian', 'Dorian', 'Dorian', 'Dorian', 'Dorian', 'Dorian', 'Erwan', 'Erwan', 'Erwan', 'Erwan', 'Erwan', 'Erwan', 'Erwan', 'Erwan', 'Erwan', 'Erwan', 'Erwan', 'Erwan', 'Erwan', 'Erwan', 'Erwan', 'Florentin', 'Florentin', 'Florentin', 'Florentin', 'Florentin', 'Florentin', 'Florentin', 'Florentin', 'Florentin', 'Florentin', 'Florentin', 'Florentin', 'Florentin', 'Florentin', 'Florentin', 'Gauthier', 'Gauthier', 'Gauthier', 'Gauthier', 'Gauthier', 'Gauthier', 'Gauthier', 'Gauthier', 'Gauthier', 'Gauthier', 'Gauthier', 'Gauthier', 'Gauthier', 'Gauthier', 'Gauthier', 'Khélian', 'Khélian', 'Khélian', 'Khélian', 'Khélian', 'Khélian', 'Khélian', 'Khélian', 'Khélian', 'Khélian', 'Khélian', 'Khélian', 'Khélian', 'Khélian', 'Khélian', 'Marius', 'Marius', 'Marius', 'Marius', 'Marius', 'Mathieu', 'Mathieu', 'Mathieu', 'Mathieu', 'Mathieu', 'Maxime', 'Maxime', 'Maxime', 'Maxime', 'Maxime', 'Maxime', 'Maxime', 'Maxime', 'Maxime', 'Maxime', 'Maxime', 'Maxime', 'Maxime', 'Maxime', 'Maxime', 'Nouveau dossier', 'Nouveau dossier', 'Nouveau dossier', 'Nouveau dossier', 'Nouveau dossier', 'Nouveau dossier', 'Nouveau dossier', 'Nouveau dossier', 'Nouveau dossier', 'Nouveau dossier', 'Nouveau dossier', 'Nouveau dossier', 'Nouveau dossier', 'Nouveau dossier', 'Nouveau dossier', 'Samuel', 'Samuel', 'Samuel', 'Samuel', 'Samuel', 'Sylvain', 'Sylvain', 'Sylvain', 'Sylvain', 'Sylvain', 'Sylvain', 'Sylvain', 'Sylvain', 'Sylvain', 'Sylvain', 'Sylvain', 'Sylvain', 'Sylvain', 'Sylvain', 'Sylvain', 'Thomas', 'Thomas', 'Thomas', 'Thomas', 'Thomas', 'ThomasS', 'ThomasS', 'ThomasS', 'ThomasS', 'ThomasS', 'ThomasS', 'ThomasS', 'ThomasS', 'ThomasS', 'ThomasS', 'ThomasS', 'ThomasS', 'ThomasS', 'ThomasS', 'ThomasS', 'Unknown', 'Unknown', 'Unknown', 'Unknown', 'Unknown', 'Unknown', 'Unknown']\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Image data of dtype object cannot be converted to float",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15568/3304354619.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m84\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"gray\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, filternorm, filterrad, resample, url, data, **kwargs)\u001b[0m\n\u001b[0;32m   2901\u001b[0m         \u001b[0mfilternorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2902\u001b[0m         data=None, **kwargs):\n\u001b[1;32m-> 2903\u001b[1;33m     __ret = gca().imshow(\n\u001b[0m\u001b[0;32m   2904\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcmap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maspect\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maspect\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2905\u001b[0m         \u001b[0minterpolation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvmin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1359\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1360\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1361\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1362\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1363\u001b[0m         \u001b[0mbound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[0;32m   5607\u001b[0m                               resample=resample, **kwargs)\n\u001b[0;32m   5608\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5609\u001b[1;33m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5610\u001b[0m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5611\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36mset_data\u001b[1;34m(self, A)\u001b[0m\n\u001b[0;32m    698\u001b[0m         if (self._A.dtype != np.uint8 and\n\u001b[0;32m    699\u001b[0m                 not np.can_cast(self._A.dtype, float, \"same_kind\")):\n\u001b[1;32m--> 700\u001b[1;33m             raise TypeError(\"Image data of dtype {} cannot be converted to \"\n\u001b[0m\u001b[0;32m    701\u001b[0m                             \"float\".format(self._A.dtype))\n\u001b[0;32m    702\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Image data of dtype object cannot be converted to float"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(len(names))\n",
    "print(len(images))\n",
    "print(names)\n",
    "for i, img in enumerate(images) :\n",
    "    if(i == 84) :\n",
    "        plt.figure()\n",
    "        plt.imshow(img, cmap=\"gray\")\n",
    "        plt.axis(False)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ecd170",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_face(img, idx):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(img, 1.3, 5)\n",
    "    try :\n",
    "        x, y, w, h = faces[0]\n",
    "\n",
    "        img = img[y:y+h, x:x+w]\n",
    "        img = cv2.resize(img, (100, 100))\n",
    "    except :\n",
    "        print(\"Face not found in image index\", i)\n",
    "        img = None\n",
    "    return img\n",
    "cv2.waitKey(0)        \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c9b1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "croped_images = []\n",
    "for i, img in enumerate(images) :\n",
    "    img = detect_face(img, i)\n",
    "    if img is not None :\n",
    "        croped_images.append(img)\n",
    "    else :\n",
    "#         print(\"found\")\n",
    "#         img = cv2.resize(img, (256,256), interpolation = cv2.INTER_AREA)\n",
    "#         print(\"cut\")\n",
    "#         cv2.imshow(img)\n",
    "#         print(\"showed\")\n",
    "        del names[i]\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f2bb74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for label in labels:  \n",
    "    ids = np.where(label== np.array(names))[0]\n",
    "    images_class = croped_images[ids[0] : ids[-1] + 1] # select croped images for each class\n",
    "    show_dataset(images_class, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df99830",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_vec = np.array([np.where(name == labels)[0][0] for name in names])\n",
    "print(len(name_vec))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9de02c4e",
   "metadata": {},
   "source": [
    "Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298c94a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = cv2.face.EigenFaceRecognizer_create()\n",
    "# model = cv2.face.FisherFaceRecognizer_create()\n",
    "model = cv2.face.LBPHFaceRecognizer_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8942eb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(croped_images, name_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d824927",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save & load model\n",
    "model.save(\"eigen_model.yml\")\n",
    "model.read(\"eigen_model.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76858eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test model\n",
    "path = \"lib_test/AlexandreF1.jpg\"\n",
    "img = cv2.imread(path)\n",
    "img = detect_face(img, 0)\n",
    "\n",
    "idx, confidence = model.predict(img)\n",
    " \n",
    "print(\"Found: \", labels[idx])\n",
    "print(\"Confidence: \", confidence)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.axis(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f86804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_folder = \"lib_test/\"\n",
    "# actual_names = []\n",
    "# predicted_names = []\n",
    "# confidences = []\n",
    "# for filename in os.listdir(test_folder):\n",
    "#     if filename.find(\".jpg\") > -1:\n",
    "#         path = os.path.join(test_folder, filename)\n",
    "        \n",
    "#         img = cv2.imread(path)\n",
    "#         img = detect_face(img, 0)\n",
    "\n",
    "#         idx, confidence = model.predict(img)\n",
    "#         print(filename)\n",
    "#         actual_names.append(np.where(filename[:-5] == labels)[0][0]) #get label from filename (remove 9 last char)\n",
    "#         predicted_names.append(idx)\n",
    "#         confidences.append(confidence)\n",
    "        \n",
    "#         print(\"Actual \\t: \", filename)\n",
    "#         print(\"Predic \\t: \", labels[idx])\n",
    "#         print(\"Confidence \\t: \", confidence)\n",
    "\n",
    "#         plt.figure()\n",
    "#         plt.imshow(img, cmap=\"gray\")\n",
    "#         plt.axis(False)\n",
    "#         plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5747ea36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test real time video \n",
    "def draw_ped(img, label, x0, y0, xt, yt, color=(255,127,0), text_color=(255,255,255)):\n",
    "\n",
    "    (w, h), baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "    cv2.rectangle(img,\n",
    "                  (x0, y0 + baseline),  \n",
    "                  (max(xt, x0 + w), yt), \n",
    "                  color, \n",
    "                  2)\n",
    "    cv2.rectangle(img,\n",
    "                  (x0, y0 - h),  \n",
    "                  (x0 + w, y0 + baseline), \n",
    "                  color, \n",
    "                  -1)  \n",
    "    cv2.putText(img, \n",
    "                label, \n",
    "                (x0, y0),                   \n",
    "                cv2.FONT_HERSHEY_SIMPLEX,     \n",
    "                0.5,                          \n",
    "                text_color,                \n",
    "                1,\n",
    "                cv2.LINE_AA) \n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c628543a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened() :\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.1, 5)\n",
    "        for (x, y, w, h) in faces:\n",
    "            \n",
    "            face_img = gray[y:y+h, x:x+w]\n",
    "            face_img = cv2.resize(face_img, (100, 100))\n",
    "                \n",
    "            idx, confidence = model.predict(face_img)\n",
    "            #label_text = \"%s (%.2f %%)\" % (labels[idx], confidence)\n",
    "            label_text = \"%s\" % (labels[idx])\n",
    "\n",
    "            frame = draw_ped(frame, label_text, x, y, x + w, y + h, color=(0,255,255), text_color=(50,50,50))\n",
    "       \n",
    "        cv2.imshow('Detect Face', frame)\n",
    "    else :\n",
    "        break\n",
    "    if cv2.waitKey(10) == ord('q'):\n",
    "        break\n",
    "cv2.waitKey(0)        \n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ebdce224",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
